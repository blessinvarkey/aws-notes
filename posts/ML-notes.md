
## Bias
High bias can cause an algorithm to miss the relevant relations between features and target outputs (underfitting)

### Underfitting, Overfitting, Balanced

![alt-text](https://docs.aws.amazon.com/machine-learning/latest/dg/images/mlconcepts_image5.png)

## Bootstrap
Bootstrap simulates obtaining many new datasets by repeated sampling with replacement from the origional dataset. 

## Bagging 

## Boosting
An ensemble learning strategy that trains a series of weak models, each one attempting to correctly predict the observations the previous model got wrong. 

## Bayesian Methods
- Works well even with small data.  
- Computationally costly in large data.  
- A prior must be chosen.   

# Greedy Algorithm
'Greedy algorithms take all of the data in a particular problem, and then set a rule for which elements to add to the solution at each step of the algorithm. In the animation above, the set of data is all of the numbers in the graph, and the rule was to select the largest number available at each level of the graph. The solution that the algorithm builds is the sum of all of those choices.' via [Brilliant](https://brilliant.org/wiki/greedy-algorithm/)

# Logistic regression 
- Used in classification problems 
- Predictive modelling algorithm
- It uses sigmoid function (logistic) to find the relationship between variables

# Support Vector Machine
- Can be used for both classification and regression problems but is mostly used for solving classification problems




# SOM
# t-SNE
# k-means
# PLS-DA
# random forests


## Image sources: 
I1:  [Overfitting, Biased and Balanced via AWS Documentation](https://docs.aws.amazon.com/machine-learning/latest/dg/images/mlconcepts_image5.png)
